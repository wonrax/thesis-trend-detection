\section{Các mô hình}
\label{sec:models}
Ta thường có hai cách để phát hiện các sự kiện hay chủ đề đang nổi bật:
\textbf{(1)} hồi tưởng (retrospect), sử dụng toàn bộ dữ liệu để làm đầu vào cho
mô hình, hoặc, \textbf{(2)} online, phát hiện trên thời gian thực bằng cách đưa
vào (feed) mô hình mỗi khi ta thu thập được dữ liệu
mới~\cite{lauOnlineTrendAnalysis2012}. Với cách \textbf{(1)}, ta có thể phân
tích được các chủ đề hay sự kiện trong lịch sử, và thường được hiện thực bằng
các phương thức như gọm cụm (clustering) hay phát hiện bất thường (anomaly
detection). Tuy nhiên, nếu ta muốn phát hiện các sự kiện đang xảy ra trong thời
gian thực, chẳng hạn như phát hiện động đất, thì ta cần dùng đến kỹ thuật thứ
\textbf{(2)}.

Ba mô hình chính được báo cáo này nhắc tới bao gồm mô hình phát hiện xu hướng
(được xếp vào kỹ thuật thứ \textbf{2}), mô hình phát hiện chủ đề và mô hình
phát hiện chủ đề dựa trên ngữ nghĩa (được xếp vào kỹ thuật thứ \textbf{1}).  Mô
hình phát hiện xu hướng được nghiên cứu là mô hình được phát triển bởi
Twitter~\cite{hendricksonTrendDetectionSocial2015}, bao gồm mô hình xác suất và
mô hình thiên dữ liệu (data-driven). Mô hình phát hiện chủ đề là mô hình khai
thác sự xuất hiện của các từ khoá trong các tập văn bản để tìm ra sự tương quan
giữa các từ khoá và sự ảnh hưởng của từ khoá đối với chủ đề của văn bản. Mô
hình phát hiện chủ đề mà báo cáo này sẽ tập trung nghiên cứu là mô hình Latent
Dirichlet Allication (LDA). Mô hình phát hiện chủ đề dựa trên ngữ nghĩa là một
mô hình phát hiện chủ đề nhưng được dựa trên ngữ nghĩa của văn bản, hay ngữ
cảnh mà văn bản đó biểu hiện để thực hiện gom cụm chủ đề. Mô hình ngữ nghĩa
BERT và PhoBERT là đối tượng nghiên cứu và là cơ sở cho thực nghiệm, được kết
hợp với LDA và phương pháp gom cụm để có thể sinh ra kết quả tốt
hơn~\cite{lamGomCumVan2021}.



\subsection{Mô hình phát hiện xu hướng}
Tương tác của người dùng trên mạng xã hội luôn có sự liên quan nhất định nào đó
đến các sự kiện ở ngoài thế giới
thực~\cite{hendricksonTrendDetectionSocial2015}. Để phát hiện xu hướng, ta cần
phải trả lời các câu hỏi như: sự kiện đó bắt đầu từ khi nào? Mức độ thay đổi
phạm vi của sự kiện này là lớn hay nhỏ? Và chúng thay đổi như thế nào đối với
các sự kiện bình thường (typical) khác? Việc này không chỉ giúp phân biệt giữa
các sự kiện bình thường và các sự kiện bất thường (atypical) mà còn giúp so
sánh các sự kiện bất thường với
nhau~\cite{hendricksonTrendDetectionSocial2015}.

Twitter là mạng xã hội cho phép người dùng đăng các bài đăng, hay còn được gọi
là Tweet. Trong một Tweet, người dùng có thể thêm văn bản (giới hạn 280 ký tự)
hoặc hình ảnh. Mô hình của Twitter định lượng các hành vi người dùng bằng cách
đếm hashtag, mention hoặc liên kết (link) trong một khoảng thời gian cố định
(bucketed count). Khi một định lượng được thể hiện bằng một từ hoặc cụm từ, ta
có thể gọi từ hoặc cụm từ đó là \textit{chủ
đề}~\cite{hendricksonTrendDetectionSocial2015}.

Tuy nhiên, ta không thể biết trước được mức độ của sự thay đổi, hay thời gian
mà sự thay đổi đó sẽ xảy ra. Có sự kiện chỉ diễn ra trong một vài giây, có sự
kiện có thể diễn ra trong hàng năm. Hơn nữa, định lượng cho các sự kiện đó có
thể thay đổi từ một vài Tweet cho đến hàng triệu Tweet. Để phát triển một giải
thuật có thể đáp ứng được các kích thước dữ liệu trên phạm vi rộng lớn là việc
không hề đơn giản~\cite{hendricksonTrendDetectionSocial2015}.

Nhiều kỹ thuật dùng để phát hiện xu hướng đều định nghĩa một mô hình cơ sở
(background model), là mô hình có thể đại diện cho giả thuyết không (null
hypothesis), về cơ bản có nghĩa là \textit{không trend} (không là xu hướng).
Những thay đổi của các định lượng so với mô hình cơ sở (deviation) được tính
toán thành một hệ số (figure-of-merit) $\eta$. Giá trị $\eta$ càng lớn thì sự
thay đổi của định lượng so với mô hình cơ sở càng nhiều. Và một giá trị $\eta$
được định nghĩa trước có thể được sử dụng để chấp nhận hoặc từ chối giả thuyết
không~\cite{hendricksonTrendDetectionSocial2015}.

Một kỹ thuật khác có thể bao gồm thành phần cơ sở (non-trend, hay \textit{không
trend}) và thành phần giống trend (trend-like, hay \textit{đang là xu hướng}).
Khi đó, giá trị $\eta$ sẽ thể hiện cho việc dữ liệu sẽ giống \textit{trend} hơn
hay dữ liệu sẽ giống \textit{không trend}
hơn~\cite{hendricksonTrendDetectionSocial2015}.

\subsubsection{Mô hình xác xuất Poisson}

Phân phối Poisson là phân phối xác suất rời rạc, dùng để thể hiện xác suất số
lần một sự kiện nào đó xảy ra trong một khoảng thời gian nhất
định~\cite{haightHandbookPoissonDistribution1967}. Vì vậy, phân phối Poisson có
khả năng áp dụng cho việc định lượng dữ liệu trên mạng xã hội, hay nói cách
khác, ta có thể mặc định dữ liệu đó tuân theo phân phối
Poisson~\cite{hendricksonTrendDetectionSocial2015}.

Ví dụ, ta xét số lượng Tweet có chứa hashtag "\#covid19" trong một khoảng thời
gian nhất định. Tần suất đăng bài của người dùng có thể thay đổi theo thời
gian. Nhưng nếu ta bỏ qua sự thay đổi đó, ta có thể nói, số lượng Tweet có chứa
hashtag "\#covid19" tuân theo phân phối Poisson:
\[ P\left(c_{i} ; \nu\right)=\nu^{c_{i}} \cdot e^{-\nu} / c_{i} ! \]

với:
\begin{itemize}
	\item $c_{i}$ là số lượng Tweet có chứa hashtag "\#covid19" trong một khoảng
	thời gian nhất định.
	\item $P$ là xác suất xuất hiện các Tweet có chứa hashtag "\#covid19" với số
	lượng $c_{i}$.
	\item $\nu$ là số lượng kỳ vọng các Tweet có chứa hashtag "\#covid19".
\end{itemize}

Vì ta không thể biết chính xác giá trị $\nu$, nên ta có thể lấy số lượng Tweet ở
khoảng thời gian trước đó (đã biết) là $c_{i - 1}$ để biểu diễn cho $\nu$. Ta có
hệ số $\eta$ tại một thời điểm nào đó là:
\[ c_{i}=\eta \cdot \mathrm{CI}(\alpha, \nu)+\nu \]

với:
\begin{itemize}
	\item $\nu=c_{i-1}$.
	\item $CI(\alpha, \nu)$ là khoảng tin cậy (confidence interval) cho phân
	phối Poisson với mean $\nu$ và độ tin cậy $\alpha$.
\end{itemize}

Khi đó, một số lượng Tweet $c_{i}$ được định nghĩa để có thể từ chối giả thuyết
khi:
\[
	c_{i}>=\eta_{c} \cdot \operatorname{CI}\left(\alpha, c_{i-1}\right)+c_{i-1}
\]

với $\eta_{c}$ và $\alpha$ là các tham số để điều chỉnh hiệu suất của thuật
toán~\cite{hendricksonTrendDetectionSocial2015}.

Trên thực tế, dữ liệu thường không tuân theo phân phối Poisson với mean chỉ đơn
giản là một điểm dữ liệu. Để giải quyết vấn đề này, ta có thể tính mean bằng
giá trị trung bình của nhiều điểm dữ liệu trong lịch sử trong cùng một sliding
window. Tuy nhiên, ta không thể bỏ qua tần suất hoạt động của người dùng trong
ngày, trong tháng hoặc trong năm. Chẳng hạn như, người dùng có xu hướng đăng
Tweet nhiều nhất trong ngày vào lúc 17h-20h. Cho nên, khi ta bắt gặp sự thay
đổi đáng kể trong khoảng thời gian đó, ta không thể đơn giản kết luận đó là xu
hướng.

Mô hình trên khá đơn giản và chỉ yêu cầu một điểm hoặc vài điểm dữ liệu cho mô
hình cơ sở. Tuy nhiên với lượng dữ liệu thay đổi liên tục và thay đổi trong
phạm vi rộng, ta không thể tìm được một cặp tham số $\eta$ và $\alpha$ tối ưu
cho mọi loại dữ liệu.

\subsubsection{Mô hình thiên dữ liệu (data-driven)}
Để giải quyết các vấn đề của mô hình Poisson,
\cite{hendricksonTrendDetectionSocial2015}~đề xuất phương pháp đơn giản hơn đó
là so sánh dữ liệu cần phân tích với các dữ liệu đã được gán nhãn. Trước tiên,
ta phải phân loại dữ liệu có sẵn thành \textit{đang trend} hoặc \textit{không
trend}. Sau đó, ta định nghĩa một hàm tính khoảng cách từ dữ liệu đã gán nhãn
và dữ liệu ta cần phân tích:
\[ d(r, s)=\sum_{i}^{N}\left(r_{i}-s_{i}\right)^{2} \]

với:
\begin{itemize}
	\item $r$ là dữ liệu dạng time series đã được gán nhãn.
	\item $s$ là dữ liệu dạng time series đang được phân tích.
	\item $r_{i}$ và $s_{i}$ là các giá trị của dữ liệu tại thời điểm $i$ trong
	tập dữ liệu $r$ và $s$ có độ dài $N$.
\end{itemize}

Nếu $r$ có độ dài lớn hơn $s$, ta lấy giá trị nhỏ nhất trong các khoảng cách
$d(r_s, s)$, với $r_s$ là tập con (sub-series) của $r$. Với hàm khoảng cách ở
trên, ta có thể tính trọng lượng (weight) bằng cách:
\[ W(r,s)=e^{-\lambda \cdot d(r,s)} \]

Tham số $\lambda$ là một hệ số để điều chỉnh mức độ quan trọng giữa các time
series khác nhau hoặc giống nhau. Ví dụ, giá trị $\lambda$ lớn cho ra $W$ rất
nhỏ kể cả khi khoảng cách $r$ và $s$ là rất lớn. Khi đó, $\eta$ sẽ được tính
bằng tỉ lệ:
\[
\eta(s)=\frac{\sum_{r \in R+} W(r, s)}{\sum_{r \in R-} W(r, s)}
\]

với $R+$ là tập dữ liệu gồm nhiều time series được gán nhãn \textit{trend} và
$R-$ là dữ liệu được gán nhãn \textit{không trend}. Giá trị $\eta$ càng cao thì
time series $s$ càng \textit{giống trend} và ngược lại.

Khó khăn chính khi hiện thực mô hình này là việc gán nhãn cho các dữ liệu
\textit{đang trend} và \textit{không trend}. Bên cạnh đó, để mô hình hoạt động
trên mọi kích thước dữ liệu, việc thực hiện biến đổi (transformation) trên các
tập dữ liệu là cần thiết. Các biến đổi có thể là~\cite{nikolovTrendNoTrend2012}:

\begin{itemize}
	\item \textbf{Chuẩn hoá đường cơ sở (Baseline Normalization)}: Quan sát cho
		thấy khá nhiều chủ đề \textit{không trend} có tần suất Tweet rất cao,
		bên cạnh đó cũng có rất nhiều chủ đề \textit{đang trend} lại có tần
		suất Tweet rất thấp. Ví dụ, chủ đề "city" có tần suất cơ sở (baseline
		rate) rất cao vì nó là một âm tiết phổ biến trong tiếng Anh. Vì vậy nên
		ta có thể sử dụng Baseline Normalization để nhấn mạnh (emphasize) các
		điểm dữ liệu cao hơn đường cơ sở và giảm độ quan trọng của các điểm dữ
		liệu thấp hơn đường cơ sở.
	
	\item \textbf{Chuẩn hoá spike (Spike Normalization)}: Các chủ đề
		\textit{đang trend} và các chủ đề \textit{không trend} còn khác nhau ở
		độ lớn và tần suất của các điểm spike (điểm có giá trị lớn đột ngột).
		Vì vậy, Spike Normalization giúp nhấn mạnh các điểm spike và ngược lại.
	
	\item \textbf{Thang đo lôgarit (Logarithmic Scale)}: Ta thường không thể
		biết được cách thức mà một chủ đề được lan toả ra khắp cộng đồng, nhưng
		ta biết được đa số các quá trình phân nhánh (branching process) đều
		phát sinh theo cấp số mũ. Vì vậy, ta có thể sử dụng thang đo lôgarit để
		định lượng, qua đó có thể khai thác các đặc điểm này.

\end{itemize}

Mặc dù dữ liệu được dán nhãn sẽ quyết định kết quả của một time series, nhưng
ta vấn có thể điều chỉnh mô hình bằng cách thay đổi các tham số như $\lambda$,
độ dài time series $s$ và $r$, chọn các phương thức biến đổi để đạt được kết
quả tốt nhất, vì nhiều trong số chúng có ảnh hưởng trực tiếp tới các chỉ số như
true-positive và false-positive~\cite{hendricksonTrendDetectionSocial2015}.

\subsection{Mô hình phát hiện chủ đề}
Chủ đề là vấn đề cơ bản, là nội dung trọng tâm mà người nói hoặc người viết
muốn đề cập. Một văn bản (bài báo, Tweet, bài văn, v.v.) có thể chứa nhiều chủ
đề, nhưng chỉ có một hoặc một vài chủ đề có thể làm chủ đề chính để đại diện
cho văn bản đó.

Để tìm ra chủ đề, ta không thể đơn giản chỉ tìm từ phổ biến nhất trong văn bản.
Mỗi từ tuỳ theo ngữ cảnh có thể thuộc về nhiều chủ đề khác nhau. Ví dụ như âm
tiết "đường" có thể vừa thuộc chủ đề "gia vị" và vừa có thể thuộc chủ đề "công
trình". Mô hình phát hiện chủ đề là mô hình túi từ (bag-of-words model) dùng để
khai thác mối tương quan giữa các từ và các chủ đề ngữ nghĩa tiềm ẩn (latent
sematic theme) giữa các văn bản~\cite{madaniRealtimeTrendingTopics2015}.

Về cơ bản, mô hình chủ đề thực hiện ba công
việc~\cite{kapadiaTopicModelingPython2020}:

\begin{itemize}
	\item \textbf{Giảm chiều (Dimensionality Reduction)}: thay vì biểu diễn từ
		T ở không gian đặc trưng (feature space) \{Word\_i: count(Word\_i, T)
		for Word\_i in Vocabulary\}, ta có thể biểu diễn nó thành \{Topic\_i:
		Weight(Topic\_i, T) for Topic\_i in Topics\}.
	
	\item \textbf{Học không giám sát (Unsupervised Learning)}: có thể so sánh
		với gom cụm, khi số lượng cụm hay số lượng chủ đề là tham số cho đầu ra
		của mô hình. Khi ta thực hiện mô hình chủ đề, ta gọm cụm các từ thay vì
		gom cụm các văn bản.
	
	\item \textbf{Gán nhãn (Tagging)}: tìm cách biểu diễn các chủ đề mà các văn
		bản trong một tập văn bản thể hiện.
\end{itemize}

\subsubsection{Mô hình Latent Dirichlet Allocation (LDA)}
Mô hình LDA là mô hình tạo sinh xác suất (generative probabilistic model) cho
các dữ liệu rời rạc như các kho văn bản (text corpora). LDA là mô hình Bayes ba
lớp, với mỗi văn bản trong một tập văn bản được biểu diễn thông qua một tập các
chủ đề. Và mỗi chủ đề được biểu diễn bằng một tập các xác suất chủ
đề~\cite{bleiLatentDirichletAllocation2003}. Nói cách khác, một văn bản có thể
biểu diễn bằng nhiều chủ đề, và một chủ đề có thể được biểu diễn bằng nhiều từ
khác nhau.

Giả sử ta có 1000 văn bản, và mỗi văn bản có trung bình 300 từ. Để biết được thể
loại của mỗi văn bản, ta có thể nối mỗi văn bản với các từ xuất hiện trong văn
bản đó (Hình \ref{fig:simple_word_doc_model}). Khi đó, một tập các văn bản kết
nối cùng với một tập các từ thì chúng được gọi là cùng chủ
đề~\cite{ganegedaraIntuitiveGuideLatent2021}. Tuy nhiên, số kết nối ta phải tính
toán là quá lớn: $1000 \cdot 300 = 300000$.

\image[0.7]{img/lda/simple_word_doc_model.jpeg}{Mô hình kết nối văn bản - từ đơn
giản. Ảnh:
Medium~\cite{ganegedaraIntuitiveGuideLatent2021}}{fig:simple_word_doc_model}

Để giảm số kết nối, LDA thêm một lớp tiềm ẩn (latent), tức là các chủ đề ẩn chứa
trong các văn bản đều bị ẩn đi (unknown)(Hình \ref{fig:latent_word_doc_model}).
Tuy nhiên chúng vẫn được thể hiện bằng cách tạo sinh văn bản dựa trên các chủ đề
đó~\cite{tomarTopicModelingUsing2019}.

\image[0.7]{img/lda/latent_word_doc_model.jpeg}{Mô hình có lớp tiềm ẩn giúp giảm
số lượng kết nối (thread). Ảnh:
Medium~\cite{ganegedaraIntuitiveGuideLatent2021}}{fig:latent_word_doc_model}

\image[0.7]{img/lda/architecture.png}{Minh hoạ mô hình LDA. Các node thể hiện
cho các biến ngẫu nhiên, các cạnh thể hiện sự phụ thuộc giữa các biến ngẫu
nhiên. Node màu xám là biến ngẫu nhiên có thể quan sát được; node màu trắng là
các biến ngẫu nhiên ẩn (hidden). Các hình chữ nhật là ký hiệu tấm (plate
notation), thể hiện sự lặp lại của các biến ngẫu nhiên
~\cite{bleiTopicModels2009}.}{fig:lda_architecture}

Hình \ref{fig:lda_architecture} minh hoạ mô hình LDA. Quá trình tạo sinh từng
văn bản $w$ trong kho văn bản $D$ được thực hiện như
sau~\cite{bleiLatentDirichletAllocation2003}:

\begin{enumerate}
	\item Chọn $N \sim Poisson(\xi)$.
	\item Chọn $\theta \sim Dir(\alpha)$ với $Dir$ là phân phối Dirichlet.
	\item Với mỗi từ $w_n$ trong N từ:
	\begin{enumerate}
		\item Chọn $z_n \sim Multinomial(\theta)$.
		\item Chọn một chủ đề $z_n$ từ $p(w_n|z_n,\beta)$, là một xác suất đa
		thức có điều kiện phụ thuộc vào chủ đề $z_n$.
	\end{enumerate}
\end{enumerate}

% # TODO \subsubsection{Phát hiện trend twitter với LDA}

\subsection{Phương pháp khai thác ngữ nghĩa}
\subsubsection{Word embedding, sentence embedding}
Véc-tơ ngữ nghĩa (vectors semantics) là phương pháp cơ bản để biểu diễn nghĩa
của các từ trong xử lý ngôn ngữ tự nhiên. Ý tưởng của véc-tơ ngữ nghĩa là
chuyển một từ thành một điểm trong không gian ngữ nghĩa (semantic space). Điểm
mà một từ thể hiện sẽ được rút ra từ sự phân bổ các điểm (từ) xung quanh nó
(neighbor). Véc-tơ dùng để biểu diễn một từ gọi là word
embedding~\cite{jurafskySpeechLanguageProcessing}.

\image[0.7]{img/bert/word-embedding.png}{Minh hoạ các véc-tơ ngữ nghĩa của từ,
các từ gần nhau thường sẽ mang ý nghĩa/ý nghĩa sử dụng gần nhau. Ảnh:
Medium~\cite{bujokasCreatingWordEmbeddings2020}.}{fig:word_embedding}

Sentence embedding cũng giống như word embedding, nhưng nó dùng để biểu diễn sự
tương quan ngữ nghĩa giữa các câu. Một cách đơn giản để tạo sentence embedding
là lấy trung bình tất cả các word embedding của các từ trong câu
đó~\cite{lamGomCumVan2021}. Sentence embedding giúp ta khai thác được ngữ cảnh rộng hơn, trải dài qua nhiều câu mà các word embedding không thể làm được.

Sentence embedding có thể sử dụng để phân loại (ví dụ, câu đang xét là mang ý
nghĩa tích cực hay tiêu cực), phân tích ngữ nghĩa (ví dụ, phân tích sự liên
quan giữa hai câu bất kỳ) hoặc dùng trong các tác vụ ngôn ngữ (linguistic task,
ví dụ, xác định động từ là thì hiện tại hay thì quá khứ trong tiếng
Anh)~\cite{heidenreichPaperSummaryEvaluation2018}.

\subsubsection{Mô hình BERT}

\subsection{VnCoreNLP}
