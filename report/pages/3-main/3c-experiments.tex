\section{Thử nghiệm}
\label{sec:experiments}

Báo cáo này tập trung thử nghiệm phân cụm dữ liệu văn bản dựa trên mô hình chủ
đề và cách kết hợp các mô hình do Nguyễn Văn Quyền Lâm đề
xuất~\cite{lamGomCumVan2021}.

Mô hình được đề xuất sử dụng véc-tơ xác suất được LDA sinh ra để xác định các
chủ đề chính yếu, sau đó chúng được kết hợp với véc-tơ sentence embedding của
PhoBERT để khai thác ngữ nghĩa, qua đó tạo ra không gian véc-tơ mới. Không gian
véc-tơ này sẽ được đi qua Autoencoder để giảm chiều, mục đích là để loại bỏ các
đặc trưng nhiễu và chỉ tập trung vào các đặc trưng quan trọng, và vừa có thể
giảm chi phí và thời gian tính toán. Cuối cùng, các véc-tơ này sẽ được đi qua
bộ phân cụm \textit{k}-means++ để phân thành \textit{k} chủ đề.

\image[0.7]{img/main-architect/proposed-architect.pdf}{Minh hoạ kiến trúc mô
hình được đề xuất.}{fig:main_architect}

\subsection{Tập dữ liệu, xử lý dữ liệu}

Nguồn dữ liệu chính là các bài báo Tuổi Trẻ (tuoitre.vn) ở danh mục \textit{Sức
khoẻ}. Báo cáo sử dụng chương trình Python để thu thập các bài báo. Các dữ liệu
thu thập được từ một bài báo bao gồm đoạn trích tóm tắt, nội dung bài viết,
ngày đăng, các bình luận, số lượng thích (like) bài báo nhận được và các từ
khoá (keyword) của bài báo do người viết đặt. Tuy nhiên, chỉ duy nhất nội dung
bài báo được lấy làm dữ liệu trực tiếp cho mô hình. Tổng số bài báo thu thập
được là 12732 bài, trải dài từ ngày tháng 9 năm 2019 đến tháng 11 năm 2021.

Trước khi đưa vào mô hình, dữ liệu cần được làm sạch và chuẩn hoá
(normalization) để tránh lỗi trong quá trình huấn luyện:
\begin{enumerate}
    \item Loại bỏ các bài báo không có nội dung (có chứa cột mang giá trị
        \textit{NULL}).
    \item Chuẩn hoá (normalize) các ký tự unicode. Chữ cái tiếng Việt có dấu
        tuy luôn luôn hiển thị giống nhau nhưng sẽ được viết bằng nhiều cách
        khác nhau. Ví dụ, chữ ``Â'' sẽ có hai cách viết: (1) là một ký tự unicode
        duy nhất ``Â'' - U+00C2, hoặc (2) được kết hợp bởi một ký tự ``A'' và một
        ký tự ``\^{}''. Chính vì vậy, ta phải chuẩn hoá chúng về một dạng để tránh
        lặp từ trong quá trình huấn luyện.
    \item Loại bỏ các ký tự đặc biệt và các stop-word (là các từ phổ biến và ít
        mang một ý nghĩa đặc trưng, ví dụ như ``là'', ``và'', v.v.).
\end{enumerate}

Sau khi được làm sạch, tập dữ liệu còn lại 12595 bài báo. Tiếp theo, ta cần đưa
nội dung các bài viết qua VnCoreNLP để phân đoạn từ. Sau khi được phân đoạn, dữ
liệu về cơ bản đã có thể được sử dụng làm đầu vào cho mô hình.

\subsection{Hiện thực mô hình}
Mô hình được hiện thực trên ngôn ngữ Python, sử dụng trình thông dịch Jupyter
Notebook trên hạ tầng Google Colab. Các mô hình con bao gồm:

\begin{itemize}
    \item Mô hình LDA sử dụng thư viện
        \textit{Gensim}~\cite{GensimTopicModelling2021}.
    \item Mô hình PhoBERT sử dụng thư viện \textit{transformers} của Hugging
        Face~\cite{wolfTransformersStateoftheArtNatural2020}. Mô hình huấn
        luyện sẵn PhoBERT\textsubscript{BASE} với chiều dài token tối đa là
        256.
    %TODO cite
    \item Autoencoder được hiện thực dựa trên mô hình mẫu của \textit{keras}.
    %TODO cite
    \item Bộ gom cụm k-means++ sử dụng thư viện \textit{sklearn}.
\end{itemize}

Sau khi gom cụm, tập dữ liệu được chia thành \textit{k} chủ đề với mỗi bài báo
chỉ thuộc một chủ đề. Lâm \cite{lamGomCumVan2021} thực hiện biểu diễn
(visualize) các chủ đề đó bằng word cloud, bằng cách lấy các từ có tần suất
xuất hiện cao nhất trong một chủ đề để làm các từ khoá thể hiện cho chủ đề đó.
Tuy nhiên, tại vì tập dữ liệu của Lâm \cite{lamGomCumVan2021} thuộc về 10 danh
mục khác nhau, nên cách biểu diễn đó có thể đã đủ để giúp người xem phân biệt
được các chủ đề. Tập dữ liệu của báo cáo chỉ thuộc về một danh mục duy nhất
(Sức khoẻ), nên thực nghiệm cho cho thấy cách biểu diễn đó khó có thể phân biệt
được các chủ đề với nhau. Lý do cơ bản là vì từ phổ biến nhất trong tập văn bản
không có nghĩa là nó có ảnh hưởng quan trọng nhất đối với chủ đề. Vì vậy, báo
cáo sử dụng TF-IDF để tính điểm (score) cho toàn bộ các từ trong một tập văn
bản thuộc cùng chủ đề đã được phân cụm. Sau đó, với mỗi văn bản, chỉ lấy $n$ từ
có điểm số cao nhất để biểu diễn thành word cloud cho chủ đề đó.

\subsection{Kết quả}
Báo cáo sử dụng thang đo Coherence để xác định tính mạch lạc trong chủ đề,
Coherence có giá trị từ 0 đến 1, giá trị càng về 0 thì chủ đề càng mất đi tính
mạch lạc; Và thang đo Silhouette để đánh giá kết quả của bộ phân cụm,
Silhouette có giá trị từ -1 đến 1, càng về 0 thì các cụm có ít sự phân biệt,
càng về 1 thì các cụm càng có sự phân biệt rõ ràng và ngược lại.
Bảng~\ref{table:result} biểu diễn kết quả của mô hình trên các giá trị gom cụm
\textit{k} khác nhau.

\begin{table}[ht!]
    \centering
    \begin{tabular}{lllllll}
        \textbf{k}          & \textit{5} & \textit{6} & \textit{7} & \textit{10} & \textit{13} & \textit{20} \\ \hline
        \textbf{Coherence}  & 0.4679     & 0.4804     & 0.5073     & 0.4915      & 0.5009      & 0.5058      \\
        \textbf{Silhouette} & 0.4036     & 0.3744     & 0.3914     & 0.3124      & 0.2927      & 0.1921     
    \end{tabular}
    \caption{Kết quả các thang đo Silhouette và Coherence với các \textit{k}
    khác nhau.}
    \label{table:result}
\end{table}

Theo dữ liệu ta có thể thấy, \textit{k} càng lớn thì điểm Coherence thường càng
cao, tuy nhiên \text{k} lớn sẽ giảm hiệu suất gom cụm đi đáng kể.

Hình~\ref{fig:clusters} minh hoạ kết quả gom cụm với $k=5$. Hình
\ref{fig:topic1}, \ref{fig:topic2}, \ref{fig:topic3}, \ref{fig:topic4},
\ref{fig:topic5}, thể hiện 5 word cloud được lọc bởi TF-IDF cho 5 chủ đề khác
nhau. Nhìn vào hình, ta có thể đoán được các chủ đề cơ bản:
\begin{enumerate}
    \item Chủ đề 1 tập trung chủ yếu về ``vắc-xin'', ``dịch'' [COVID-19], ``thuốc''
        và ``thử nghiệm'' [vắc-xin COVID-19]. Một số tựa đề bài báo được lấy ngẫu
        nhiên trong tập các bài viết cùng chủ đề:
        \begin{itemize}
            \item AstraZeneca và J\&J nối lại các thử nghiệm vắc xin COVID-19 tại Mỹ
            \item Vắc xin COVID-19 của Việt Nam được thử nghiệm trên người ra sao?
            \item EU có thể ngăn xuất khẩu hàng triệu liều vắc xin COVID-19 sang Anh
            \item Chứng chỉ hành nghề của ông Võ Hoàng Yên chỉ là giúp việc chuyên môn
            \item TP.HCM: Người dân bắt đầu khai báo hồ sơ sức khỏe điện tử
            \item TP.HCM: Xét nghiệm cho thi tốt nghiệp THPT, xác định 12 ca mắc COVID-19
            \item Sở Y tế TP.HCM xem xét cho bệnh nhân COVID-19 khỏi bệnh tình nguyện chống dịch
        \end{itemize}
    \item Chủ đề 2 có các từ ``bệnh nhân'', ``cách ly'' hay ``ca'', chúng đều thể
        hiện cho các bài viết thông tin về số ca nhiễm [COVID-19] trong ngày.
        \begin{itemize}
            \item Bắc Giang xuất hiện ổ dịch mới với 12 ca mắc ở Công ty Hosiden, sẽ lấy mẫu xuyên đêm
            \item Bệnh viện quận Tân Phú tạm ngưng nhận bệnh vì 3 ca nghi nhiễm COVID-19
            \item Virus lây lan nhanh, TP.HCM phát hiện nhiều chu kỳ lây nhiễm thứ 4, thứ 5
            \item Nam công nhân mắc COVID-19 khi từ TP.HCM về Trà Vinh
            \item Dân xếp hàng, giãn cách lấy mẫu xét nghiệm diện rộng
            \item Đồng Nai vượt 800 ca, COVID-19 lây nhiễm cộng đồng khá nhanh và rộng
            \item Hà Nội thêm 13 ca COVID-19 mới, quận Hai Bà Trưng 'làm khó' thủ tục đi đường
            TP.HCM: F0 khỏi bệnh nếu chưa được xác nhận, phải tiêm vắc xin mới có thẻ xanh COVID
        \end{itemize}
    \item Chủ đề 3 nói về các vấn đề chung về y tế như ``bác sĩ'', ``bệnh nhân''
        hay ``điều trị''.
        \begin{itemize}
            \item Ngày đêm túc trực cứu phi công người Anh
            \item Cứu sống thai nhi bị 6 vòng dây rốn quấn chặt
            \item Chuẩn bị đưa bệnh nhân phi công người Anh về quê hương
            \item Xuất hiện dịch bệnh lạ ở nơi có hàng ngàn người Việt sinh sống
            \item Tối khuya 10-8 có ca tử vong do COVID-19 thứ 4 trong ngày
            \item Bệnh nhân COVID-19 số 761 tử vong, ca tử vong thứ 35
            \item Mổ cấp cứu cụ ông bị thanh gỗ đâm xuyên phổi
            \item Trái tim anh công nhân cầu đường Vũng Tàu đập trong lồng ngực thanh niên Huế
        \end{itemize}
    \item Chủ đề 4 có các từ ``tiêm'', ``vắc-xin'', ``ca'' là phổ biến, thể hiện các
        bài viết cập nhật về tiến độ tiêm chủng.
        \begin{itemize}
            \item Thủ tướng Ấn Độ ca ngợi yoga trong điều trị COVID-19
            \item Đà Nẵng dự kiến tiêm 20.000 mũi vắc xin COVID-19 một ngày, 100-110 điểm tiêm
            \item Hai con hổ Sumatra mắc COVID-19 đã khỏi bệnh
            \item Loài người có thể ngăn chặn được biến thể Delta?
            \item Bình Dương nới lỏng giãn cách, cấp 'thẻ xanh' cho người tiêm 2 mũi vắc xin ở vùng xanh
            \item Ca nhập viện do COVID-19 ở Singapore tăng nhưng ít ca bệnh nặng
            \item Tiêm 'trộn' vắc xin Johnson \& Johnson với Moderna tăng kháng thể gấp 76 lần
        \end{itemize}
    \item Chủ đề 5 phổ biến với các từ ``bệnh'', ``trẻ'', ``thuốc'' và ``nghiên cứu'',
        về cơ bản cũng là các vấn đề chung về y tế, nhưng thiên về các mẹo hay phương pháp để cải thiện sức khoẻ.
        \begin{itemize}
            \item Người 'chịu khó' súc họng sẽ giúp mình ít nhiễm trùng hô hấp hơn
            \item Trẻ nhiễm COVID-19 mắc hội chứng lạ giống Kawasaki: làm sao phân biệt hai bệnh?
            \item Làm gì để có làn da đẹp?
            \item Những bệnh nền nào dễ khiến bệnh nhân COVID-19 gặp nguy hiểm?
            \item Bột ngọt dưới góc nhìn chuyên gia dinh dưỡng
            \item Sáng kiến kết hợp hai xét nghiệm di truyền giúp sinh con khỏe mạnh
            \item Giải mã 2 yếu tố bí ẩn nắm giữ 'bản lĩnh đàn ông'
        \end{itemize}
\end{enumerate}

\image[0.6]{img/experiments/clusters.png}{Minh hoạ kết quả gom cụm với
$k=5$.}{fig:clusters}

\image[0.6]{img/experiments/topic0.png}{Word cloud cho chủ đề thứ 1,
$k=5$.}{fig:topic1}

\image[0.6]{img/experiments/topic1.png}{Word cloud cho chủ đề thứ 2,
$k=5$.}{fig:topic2}

\image[0.6]{img/experiments/topic2.png}{Word cloud cho chủ đề thứ 3,
$k=5$.}{fig:topic3}

\image[0.6]{img/experiments/topic3.png}{Word cloud cho chủ đề thứ 4,
$k=5$.}{fig:topic4}

\image[0.6]{img/experiments/topic4.png}{Word cloud cho chủ đề thứ 5,
$k=5$.}{fig:topic5}

\subsection{Kết luận}
Áp dụng mô hình trên để thực hiện gom cụm chủ đề cho tập dữ liệu bài báo cùng
một danh mục Sức khoẻ, ta thấy sự phân biệt giữa các chủ đề mới chỉ ở ngang mức
trung bình. Tuy đã được cải thiện bằng TF-IDF, nhưng cách biểu diễn chủ đề sử
dụng word cloud vẫn còn chưa bộc lộ hết được ý nghĩa của chủ đề. Tốc độ tính
toán của mô hình đã được tăng lên đáng kể bằng cách sử dụng GPU, tuy nhiên đa
phần các nhược điểm mà \cite{lamGomCumVan2021} gặp phải vẫn chưa được giải
quyết trong báo cáo này.

\textbf{Kết quả đạt được}:
\begin{itemize}
    \item Nghiên cứu và hiểu được các kỹ thuật phát hiện xu hướng, các mô hình
        phát hiện chủ đề và phân tích ngữ nghĩa.
    \item Học được cách thu thập dữ liệu, các kỹ thuật làm sạch và tiền xử lý
        dữ liệu.
    \item Thử nghiệm dữ liệu thu thập được với mô hình có sẵn, tuy không đạt
        đuợc kết quả tốt.
\end{itemize}
