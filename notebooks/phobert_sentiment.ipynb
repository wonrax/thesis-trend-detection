{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x86UjbzitoC3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install vncorenlp\n",
        "\n",
        "!git clone https://github.com/vncorenlp/VnCoreNLP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK9beRqzuC-h",
        "outputId": "8eeaa1c8-3750-4ee2-8ee8-293d0fbfaea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 16.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 20.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0\n",
            "Collecting vncorenlp\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.10.8)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=69b6633170e1269ab5fff3d1190626a034944877258a3b594f91c096655eb15c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n",
            "Cloning into 'VnCoreNLP'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 215 (delta 0), reused 0 (delta 0), pack-reused 212\u001b[K\n",
            "Receiving objects: 100% (215/215), 214.22 MiB | 36.15 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4FZMh7__toC_",
        "outputId": "256d399d-53d8-4c2c-caa3-d57200fcb97f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 comment label  rate  \\\n",
              "0                                         Áo bao đẹp ạ!!   POS     5   \n",
              "1                                            Tuyệt vời !   POS     5   \n",
              "2                             2day ao khong giong trong.   NEG     1   \n",
              "3                            Mùi thơm,bôi lên da mềm da.   POS     5   \n",
              "4                                      Vải đẹp, dày dặn.   POS     5   \n",
              "...                                                  ...   ...   ...   \n",
              "31455                                   Không đáng tiền.   NEG     1   \n",
              "31456                                      Quần rất đẹp.   POS     5   \n",
              "31457                            Hàng đẹp đúng giá tiền.   POS     5   \n",
              "31458                                   Chất vải khá ổn.   POS     4   \n",
              "31459  áo rất ok nhé , vải mịn , len cao cổ này phối ...   POS     5   \n",
              "\n",
              "      Unnamed: 3  \n",
              "0            NaN  \n",
              "1            NaN  \n",
              "2            NaN  \n",
              "3            NaN  \n",
              "4            NaN  \n",
              "...          ...  \n",
              "31455        NaN  \n",
              "31456        NaN  \n",
              "31457        NaN  \n",
              "31458        NaN  \n",
              "31459        NaN  \n",
              "\n",
              "[31460 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fca52e88-0e97-406f-a536-e495e9cc2609\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>rate</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Áo bao đẹp ạ!!</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tuyệt vời !</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2day ao khong giong trong.</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mùi thơm,bôi lên da mềm da.</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vải đẹp, dày dặn.</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31455</th>\n",
              "      <td>Không đáng tiền.</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31456</th>\n",
              "      <td>Quần rất đẹp.</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31457</th>\n",
              "      <td>Hàng đẹp đúng giá tiền.</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31458</th>\n",
              "      <td>Chất vải khá ổn.</td>\n",
              "      <td>POS</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31459</th>\n",
              "      <td>áo rất ok nhé , vải mịn , len cao cổ này phối ...</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31460 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fca52e88-0e97-406f-a536-e495e9cc2609')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fca52e88-0e97-406f-a536-e495e9cc2609 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fca52e88-0e97-406f-a536-e495e9cc2609');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data_csv = \"reviews-ecommerce.csv\"\n",
        "dataset = pd.read_csv(train_data_csv)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "V-aGLGqjtoDB",
        "outputId": "809ed241-2d5c-42f9-8be7-5e7cf6fc484a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ddaa6fbe002e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Perform preprocessing\n",
        "import re\n",
        "\n",
        "# TODO use a teen code list\n",
        "rep = {\"k\": \"không\", \"ko\": \"không\", \"kh\": \"không\", \"đc\": \"được\", \"dc\": \"được\", \"a\": \"anh\", \"e\": \"em\", \"v\": \"vậy\", \"vs\": \"với\", \"m\": \"mình\"} # define desired replacements here\n",
        "\n",
        "# use these three lines to do the replacement\n",
        "rep_ = dict((r\"\\b{}\\b\".format(k), v) for k, v in rep.items())\n",
        "pattern = re.compile(\"|\".join(rep_.keys()), flags=re.I)\n",
        "\n",
        "dataset[\"comment\"] = dataset[\"comment\"].apply(lambda text: pattern.sub(lambda m: rep[re.escape(m.group(0)).lower()], text))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLaaRfoxtoDC",
        "outputId": "8e290df0-229a-4800-c9a6-d004f44609e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21392,) (5349,) (4719,)\n",
            "['Shop giao hàng nhanh như chớp luôn.' 'Đóng gói sp cẩn thận.'\n",
            " 'Đợi test thử vài ngày nữa xem sao !'\n",
            " 'Shop phục vụ rất tốt .Rất đáng tiền.'\n",
            " 'Áo hơi mỏng nhưng mặc đẹp, dây của áo hoàn thiện không được tốt cho lắm, mong shop khắc phục.'] ['POS' 'POS' 'NEU' 'NEU' 'POS']\n",
            "['Chất lượng sản phẩm tuyệt vời.' 'Đặt màu vàng thì ra màu gì vậy shop???'\n",
            " 'Tôi không hề nhận được sản phẩm này.' 'Áo mỏng hơn ảnh chụp.' 'Tuyệt.'] ['POS' 'NEG' 'NEG' 'NEG' 'POS']\n",
            "['Máy chụp rất ok.'\n",
            " 'Chất lượng sản phẩm tuyệt vời Đóng gói sản phẩm rất đẹp và chắc chắn Đóng gói sản phẩm rất đẹp và chắc chắn Rất đáng tiền Thời gian giao hàng rất nhanh , yêu shop.'\n",
            " 'Chất lượng tam duoc.' 'Hang rât tôt ủng hộ dài dài.' 'Vải cũng đẹp nữa.'] ['POS' 'POS' 'NEG' 'POS' 'POS']\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(dataset[\"comment\"].values, dataset[\"label\"].values, test_size=0.15, random_state=42)\n",
        "train_texts, valid_texts, train_labels, valid_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=232)\n",
        "\n",
        "print(train_texts.shape, valid_texts.shape, test_labels.shape)\n",
        "print(train_texts[:5], train_labels[:5])\n",
        "print(valid_texts[:5], valid_labels[:5])\n",
        "print(test_texts[:5], test_labels[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqHqTBKRtoDD",
        "outputId": "0ad21fa1-4bc4-4ade-be84-dbce082e531e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from vncorenlp import VnCoreNLP\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", cache_dir=\"../phobert-base\")\n",
        "rdrsegmenter = VnCoreNLP(\n",
        "    \"./VnCoreNLP/VnCoreNLP-1.1.1.jar\",\n",
        "    annotators=\"wseg,pos\",\n",
        "    max_heap_size=\"-Xmx2g\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITBgpB0stoDE",
        "outputId": "291b58f1-f6cc-4b8b-cfb2-02236e72ad93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Shop giao hàng nhanh như chớp luôn .', 'Đóng_gói sp cẩn_thận .', 'Đợi test thử vài ngày nữa xem sao !', 'Shop phục_vụ rất tốt . Rất đáng tiền .', 'Áo hơi mỏng nhưng mặc đẹp , dây của áo hoàn_thiện không được tốt cho lắm , mong shop khắc_phục .'] ['Chất_lượng sản_phẩm tuyệt_vời .', 'Đặt màu vàng thì ra màu gì vậy shop ? ? ?', 'Tôi không hề nhận được sản_phẩm này .', 'Áo mỏng hơn ảnh chụp .', 'Tuyệt .'] ['Máy chụp rất ok .', 'Chất_lượng sản_phẩm tuyệt_vời Đóng_gói sản_phẩm rất đẹp và chắc_chắn Đóng_gói sản_phẩm rất đẹp và chắc_chắn Rất đáng tiền Thời_gian giao hàng rất nhanh , yêu shop .', 'Chất_lượng tam duoc .', 'Hang rât tôt ủng_hộ dài_dài .', 'Vải cũng đẹp nữa .']\n"
          ]
        }
      ],
      "source": [
        "# PREPARE DATA BEFORE FEEDING TO MODEL\n",
        "\n",
        "# Segmentize\n",
        "train_segmented = [rdrsegmenter.tokenize(text) for text in train_texts]\n",
        "valid_segmented = [rdrsegmenter.tokenize(text) for text in valid_texts]\n",
        "test_segmented = [rdrsegmenter.tokenize(text) for text in test_texts]\n",
        "\n",
        "# Flatten and merge back into strings\n",
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]\n",
        "train_segmented = [\" \".join(flatten(t)) for t in train_segmented]\n",
        "valid_segmented = [\" \".join(flatten(t)) for t in valid_segmented]\n",
        "test_segmented = [\" \".join(flatten(t)) for t in test_segmented]\n",
        "\n",
        "print(train_segmented[:5], valid_segmented[:5], test_segmented[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg8VhWF1toDF"
      },
      "outputs": [],
      "source": [
        "# Tokenize\n",
        "train_encodings = tokenizer(train_segmented, truncation=True, padding=\"max_length\", max_length=256)\n",
        "valid_encodings = tokenizer(valid_segmented, truncation=True, padding=\"max_length\", max_length=256)\n",
        "test_encodings = tokenizer(test_segmented, truncation=True, padding=\"max_length\", max_length=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3VYIZRtoDG",
        "outputId": "efe0f188-7d9e-4b93-dc74-43ab5358abc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đợi test thử vài ngày nữa xem sao !\n",
            "[0, 15621, 13923, 1176, 515, 43, 348, 305, 423, 381, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(train_segmented[2])\n",
        "print(train_encodings[\"input_ids\"][2][:20])\n",
        "print(train_encodings[\"attention_mask\"][2][:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zmsOcZ1toDM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class EcommReviewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        \n",
        "        self.label_to_idx = {'NEG': 0, 'POS': 1, 'NEU': 2}\n",
        "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.label_to_idx[self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = EcommReviewsDataset(train_encodings, train_labels)\n",
        "val_dataset = EcommReviewsDataset(valid_encodings, valid_labels)\n",
        "test_dataset = EcommReviewsDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBtAuhIGKBgg",
        "outputId": "fe55655b-e346-479f-bbd7-360eedcd789b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INIT MODEL\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "load_options = {\n",
        "    \"local\": 0,\n",
        "    \"pretrained:\": 1\n",
        "}\n",
        "\n",
        "## Set load location here\n",
        "where_to_load = load_options[\"local\"]\n",
        "\n",
        "num_labels = 3\n",
        "# Specify locally saved model (will be ignored if loading pretrained)\n",
        "model_dir = '/content/drive/My Drive/data/models/ecomm-review-phobert-base'\n",
        "\n",
        "model = None\n",
        "\n",
        "if where_to_load == load_options[\"local\"]:\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=num_labels)\n",
        "elif where_to_load == load_options[\"pretrained\"]:\n",
        "  model_dir = \"vinai/phobert-base\"\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=num_labels, cache_dir=\"./phobert-base\")\n",
        "\n",
        "assert model is not None"
      ],
      "metadata": {
        "id": "lbuE58N24XAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "for name, p in model.named_parameters():\n",
        "  print(p.shape, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULzAare8FFd",
        "outputId": "43e2868f-db29-412a-bece-9caf516a7e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64001, 768]) roberta.embeddings.word_embeddings.weight\n",
            "torch.Size([258, 768]) roberta.embeddings.position_embeddings.weight\n",
            "torch.Size([1, 768]) roberta.embeddings.token_type_embeddings.weight\n",
            "torch.Size([768]) roberta.embeddings.LayerNorm.weight\n",
            "torch.Size([768]) roberta.embeddings.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.0.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.0.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.0.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.0.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.0.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.0.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.0.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.0.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.0.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.1.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.1.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.1.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.1.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.1.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.1.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.1.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.1.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.1.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.2.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.2.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.2.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.2.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.2.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.2.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.2.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.2.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.2.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.3.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.3.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.3.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.3.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.3.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.3.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.3.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.3.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.3.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.4.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.4.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.4.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.4.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.4.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.4.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.4.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.4.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.4.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.5.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.5.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.5.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.5.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.5.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.5.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.5.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.5.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.5.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.6.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.6.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.6.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.6.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.6.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.6.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.6.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.6.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.6.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.7.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.7.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.7.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.7.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.7.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.7.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.7.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.7.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.7.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.8.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.8.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.8.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.8.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.8.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.8.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.8.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.8.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.8.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.9.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.9.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.9.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.9.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.9.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.9.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.9.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.9.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.9.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.10.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.10.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.10.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.10.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.10.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.10.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.10.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.10.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.10.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.11.attention.self.query.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.self.query.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.11.attention.self.key.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.self.key.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.11.attention.self.value.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.self.value.bias\n",
            "torch.Size([768, 768]) roberta.encoder.layer.11.attention.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "torch.Size([3072, 768]) roberta.encoder.layer.11.intermediate.dense.weight\n",
            "torch.Size([3072]) roberta.encoder.layer.11.intermediate.dense.bias\n",
            "torch.Size([768, 3072]) roberta.encoder.layer.11.output.dense.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.output.dense.bias\n",
            "torch.Size([768]) roberta.encoder.layer.11.output.LayerNorm.weight\n",
            "torch.Size([768]) roberta.encoder.layer.11.output.LayerNorm.bias\n",
            "torch.Size([768, 768]) classifier.dense.weight\n",
            "torch.Size([768]) classifier.dense.bias\n",
            "torch.Size([3, 768]) classifier.out_proj.weight\n",
            "torch.Size([3]) classifier.out_proj.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ML8hKxCetoDN",
        "outputId": "556a2a25-0932-4b5f-e1ea-927eaede7c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 5349\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1338\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1338' max='1338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1338/1338 10:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.536400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.472400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.570300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.563500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.647800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.505100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.535500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.504600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.558200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.504300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.592100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.562300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.712000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.548100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.594800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.650100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.672100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.637200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.461200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.498600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.407900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.443400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.523300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./sentiment-results/checkpoint-500\n",
            "Configuration saved in ./sentiment-results/checkpoint-500/config.json\n",
            "Model weights saved in ./sentiment-results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./sentiment-results/checkpoint-1000\n",
            "Configuration saved in ./sentiment-results/checkpoint-1000/config.json\n",
            "Model weights saved in ./sentiment-results/checkpoint-1000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1338, training_loss=0.5497366729873179, metrics={'train_runtime': 606.2913, 'train_samples_per_second': 8.822, 'train_steps_per_second': 2.207, 'total_flos': 703696835713536.0, 'train_loss': 0.5497366729873179, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./sentiment-results',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs\n",
        "    per_device_train_batch_size=4,  # batch size per device during training\n",
        "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
        "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-5,\n",
        "#    fp16=True,                       # use 16bit float, train faster\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=val_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test set\n",
        "\n",
        "model.eval()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# test_dataset[0]['input_ids'].shape\n",
        "\n",
        "for i in range(502, 700, 10):\n",
        "  result = model(input_ids=test_dataset[i][\"input_ids\"].unsqueeze(0).to(device),\n",
        "        attention_mask=test_dataset[i][\"attention_mask\"].unsqueeze(0).to(device),\n",
        "        token_type_ids=test_dataset[i][\"token_type_ids\"].unsqueeze(0).to(device)\n",
        "        )[0]\n",
        "  _, predicted = torch.max(result, 1)\n",
        "  print(test_dataset.idx_to_label[int(predicted)], end=\"\\t\")\n",
        "  print(test_segmented[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMfS2nDcG7px",
        "outputId": "69576181-0100-49eb-bfbb-c080bb973db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS\tQuần mềm Lên dáng đẹp Đóng_gói sản_phẩm rất đẹp và chắc_chắn Shop phục_vụ rất tốt Thời_gian giao hàng rất nhanh .\n",
            "NEG\tShop phục_vụ không nhiệt_tình .\n",
            "NEG\tChất áo rất xấu .\n",
            "POS\tMong lần sau shop sẽ uy_tín hơn !\n",
            "POS\tVáy đẹp , lên dáng chuẩn chỉ mỗi cái phần eo hơi dặmmm .\n",
            "NEU\tÁo đẹp , tương_đối giống hình , vải mát nhg dễ nhăn , kiểu áo này cũng khó là ủi , đường chỉ hơi mỏng may , kém chắc chắc .\n",
            "POS\tBạn shop n.c dễ_thương .\n",
            "POS\tNói chùn là rất ưng ạ ❤️ .\n",
            "POS\tmới dùng thấy ok . đánh_giá shop 5 * .\n",
            "NEG\tBị mẹ lấy luôn rồi .\n",
            "POS\tSản_phẩm rất đẹp rất đáng tiền💋💋💋💋 .\n",
            "NEG\tTúi thơm mùi như mùi chất hoá_học , để 1 lúc đau hết cả đầu .\n",
            "POS\tNói chug 10 saooooo .\n",
            "NEU\tChất vải tạm được .\n",
            "NEG\tHàng không giống hình , cổ may hơi chật , trong hình không có túi nhưng nhận hàng lại có túi làm xấu áo .\n",
            "POS\tGối nằm rất êm .\n",
            "POS\táo với quần đều đẹp ưng_ý mình chủ shop rất nhiệt_tình dễ_thương .\n",
            "NEG\tChất_lượng sản_phẩm rất kém , áo quá mỏng , không đáng tiền , mình đã ib cho shop yêu_cầu huỷ đơn hàng , shop đồng_ý nhưng vẫn gửi đơn hàng đi , người_nhà mìh nhận áo , về bóc gói đồ ra shock không dám thử luôn .\n",
            "NEG\tĐặt mình nhưng giao size S.\n",
            "POS\tChủ shop rất nhiệt_tình 🤗 Giao hàng lại nhanh 👍 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure F1-score\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "model.eval()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# test_dataset[0]['input_ids'].shape\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "  result = model(input_ids=test_dataset[i][\"input_ids\"].unsqueeze(0).to(device),\n",
        "        attention_mask=test_dataset[i][\"attention_mask\"].unsqueeze(0).to(device),\n",
        "        token_type_ids=test_dataset[i][\"token_type_ids\"].unsqueeze(0).to(device)\n",
        "        )[0]\n",
        "  _, predicted = torch.max(result, 1)\n",
        "  y_pred.append(int(predicted))\n",
        "  y_true.append(int(test_dataset[i][\"labels\"]))"
      ],
      "metadata": {
        "id": "wrjI8BQTQhmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.metrics.f1_score(y_true, y_pred, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY8sYhqoSsVI",
        "outputId": "d0a0d08c-fb8d-496c-8f50-8e00ae4ae223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7864696284107583"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "xs07xXrWJDUs",
        "outputId": "a656918b-baef-42a2-ba93-10d87e14d89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5349\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1338' max='1338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1338/1338 02:39]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_loss': 0.48257994651794434,\n",
              " 'eval_runtime': 159.9592,\n",
              " 'eval_samples_per_second': 33.44,\n",
              " 'eval_steps_per_second': 8.365}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = '/content/drive/My Drive/data/models/'\n",
        "trainer.save_model(model_dir + 'ecomm-review-phobert-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJUGH53wJ-7c",
        "outputId": "a7366d82-1652-458e-b11f-2d4555edc416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/My Drive/data/models/ecomm-review-phobert-base\n",
            "Configuration saved in /content/drive/My Drive/data/models/ecomm-review-phobert-base/config.json\n",
            "Model weights saved in /content/drive/My Drive/data/models/ecomm-review-phobert-base/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suc_khoe_comments_df = pd.read_csv(\"/content/suc-khoe-comments-100-sampled.csv\")\n",
        "\n",
        "suc_khoe_comments_segmented = [rdrsegmenter.tokenize(text) for text in suc_khoe_comments_df['0'].values]\n",
        "\n",
        "suc_khoe_comments_segmented = [\" \".join(flatten(t)) for t in suc_khoe_comments_segmented]\n",
        "\n",
        "suc_khoe_comments_encodings = tokenizer(suc_khoe_comments_segmented, truncation=True, padding=\"max_length\", max_length=256)"
      ],
      "metadata": {
        "id": "tJPZQkYKV67A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(suc_khoe_comments_segmented[0])\n",
        "print(suc_khoe_comments_encodings[\"input_ids\"][0])\n",
        "print(suc_khoe_comments_encodings[\"attention_mask\"][0])\n",
        "print(suc_khoe_comments_encodings[\"token_type_ids\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2r8ysIOWfsI",
        "outputId": "ae4d7979-2966-4307-82c1-a70550c8d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mong phép màu đến với con . Thương con nhiều quá , cố gắn chiến_đấu vs nó con nhé ! mong tất_cả những tốt_đẹp đến bên con .\n",
            "[0, 7675, 996, 412, 30, 15, 73, 5, 3999, 73, 36, 204, 4, 2105, 1079, 1185, 7136, 231, 73, 2083, 381, 1790, 392, 21, 2296, 30, 145, 73, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# test_dataset[0]['input_ids'].shape\n",
        "\n",
        "comment_y_true = []\n",
        "comment_y_pred = []\n",
        "label_to_idx = {\n",
        "    \"NEG\": 0,\n",
        "    \"POS\": 1,\n",
        "    \"NEU\": 2\n",
        "}\n",
        "\n",
        "for i in range(len(suc_khoe_comments_encodings[\"input_ids\"])):\n",
        "  input_ids = torch.IntTensor(suc_khoe_comments_encodings[\"input_ids\"][i]).unsqueeze(0).to(device)\n",
        "  attention_mask = torch.IntTensor(suc_khoe_comments_encodings[\"attention_mask\"][i]).unsqueeze(0).to(device)\n",
        "  token_type_ids = torch.IntTensor(suc_khoe_comments_encodings[\"token_type_ids\"][i]).unsqueeze(0).to(device)\n",
        "\n",
        "  result = model(input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "        )[0]\n",
        "  _, predicted = torch.max(result, 1)\n",
        "  comment_y_pred.append(int(predicted))\n",
        "  comment_y_true.append(label_to_idx[suc_khoe_comments_df.iloc[i][1]])\n",
        "  # print(test_dataset.idx_to_label[int(predicted)], end=\"\\t\")\n",
        "  # print(suc_khoe_comments_segmented[i])\n",
        "  # print(result, end=\"\\n\\n\")"
      ],
      "metadata": {
        "id": "1FvJW2JWW80-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(comment_y_true[20:30])\n",
        "print(comment_y_pred[20:30])\n",
        "sklearn.metrics.f1_score(comment_y_true, comment_y_pred, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1IgFK9xaNf9",
        "outputId": "63b67354-962e-402f-bb96-54543549e8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 2, 2, 2, 1, 2, 2, 2, 1, 2]\n",
            "[1, 2, 2, 0, 2, 2, 2, 2, 0, 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5125837031060911"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e17fdab8067813884a193836e49f3945660fd5d00e539ef6cb2f60ea4da851c1"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "phobert-sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}